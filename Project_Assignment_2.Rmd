---
title: "Project 2: Students' Social Media Addiction Analysis"
author: "Kwizera Mugwaneza Frank"
date: "November 17, 2025"
output: word_document
---

**Research Question 1: Is daily social media usage hours associated with academic performance?**

- Explanatory Variable: Avg_Daily_Usage_Hours (Quantitative)
- Response Variable: Affects_Academic_Performance (Categorical)

**Research Question 2: Is social media addiction level associated with relationship conflicts?**

- Explanatory Variable: Addicted_Score (Quantitative)
- Response Variable: Conflicts_Over_Social_Media (Quantitative)

## 1. Load data set(s) and libraries

```{r setup, message=FALSE, warning=FALSE}
# Load required libraries
library(descr)
library(stats)

# Load the dataset
social_media_data <- read.csv("Students_Social_Media_Addiction.csv")

# Display structure of the dataset
str(social_media_data)

# Display first few rows
head(social_media_data)

# Display summary statistics
summary(social_media_data)
```

## 2. Create variable subset

```{r variable_subset}
# Create subset with only variables needed for the research project
data_subset <- social_media_data[, c("Age", 
                                      "Gender", 
                                      "Academic_Level", 
                                      "Country",
                                      "Avg_Daily_Usage_Hours", 
                                      "Most_Used_Platform",
                                      "Affects_Academic_Performance", 
                                      "Sleep_Hours_Per_Night",
                                      "Mental_Health_Score",
                                      "Relationship_Status",
                                      "Conflicts_Over_Social_Media",
                                      "Addicted_Score")]

# Verify the subset
dim(data_subset)
names(data_subset)
```

## 3. Data management I: check for and recode errors and NAs, if the need be.

```{r data_management_1}
# Check for missing values in each variable
cat("Missing values summary:\n")
colSums(is.na(data_subset))

# Check categorical variables for errors and NAs using freq() from descr package
# Gender
cat("\n Gender Frequency \n")
freq(data_subset$Gender, plot = TRUE, main = "Gender Frequency", ylab="Frequency", col="lightblue")

# Academic_Level
cat("\n Academic Level Frequency \n")
freq(data_subset$Academic_Level, plot = TRUE, main = "Academic Level Frequency", ylab="Frequency", col="lightblue")

# Country
cat("\n Country Frequency \n")
freq(data_subset$Country, plot = TRUE, main = "Country Frequency", ylab="Frequency", col="lightblue", las=2)

# Most_Used_Platform
cat("\n Most Used Platform Frequency \n")
freq(data_subset$Most_Used_Platform, plot = TRUE, main = "Most Used Platform Frequency", ylab="Frequency", col="lightblue",las=2)

# Affects_Academic_Performance
cat("\n Affects Academic Performance Frequency \n")
freq(data_subset$Affects_Academic_Performance, plot = TRUE, main = "Affects Academic Performance Frequency", ylab="Frequency", col="lightblue")

# Relationship_Status
cat("\n Relationship Status Frequency \n")
freq(data_subset$Relationship_Status, plot = TRUE, main = "Relationship Status Frequency", ylab="Frequency", col="lightblue")

# Check quantitative variables for outliers using histograms
cat("\n Quantitative Variables Summary \n")
summary(data_subset[, c("Age", "Avg_Daily_Usage_Hours", "Sleep_Hours_Per_Night", 
                        "Mental_Health_Score", "Conflicts_Over_Social_Media", "Addicted_Score")])

# Create histograms for quantitative variables
par(mfrow=c(2,3))
hist(data_subset$Age, main="Age Distribution", xlab="Age", col="lightblue", breaks=15)
hist(data_subset$Avg_Daily_Usage_Hours, main="Daily Usage Hours", xlab="Hours", col="lightgreen", breaks=20)
hist(data_subset$Sleep_Hours_Per_Night, main="Sleep Hours", xlab="Hours", col="lightcoral", breaks=15)
hist(data_subset$Mental_Health_Score, main="Mental Health Score", xlab="Score (1-10)", col="lightyellow", breaks=10)
hist(data_subset$Conflicts_Over_Social_Media, main="Conflicts Over Social Media", xlab="Number of Conflicts", col="lightpink", breaks=10)
hist(data_subset$Addicted_Score, main="Addiction Score", xlab="Score (1-10)", col="lavender", breaks=10)
par(mfrow=c(1,1))

# Data Quality Check: If No error codes or problematic NAs found my data will be  clean
```

## 4. Data management II: further subset and create secondary variable, if the need be.

```{r data_management_2}
# Create a categorical version of daily usage hours for easier analysis
data_subset$Usage_Category <- cut(data_subset$Avg_Daily_Usage_Hours,
                                   breaks = c(0, 2, 4, 6, 10),
                                   labels = c("Low (0-2h)", "Moderate (2-4h)", 
                                             "High (4-6h)", "Very High (6+h)"),
                                   include.lowest = TRUE)

# Create a categorical version of addiction score
data_subset$Addiction_Level <- cut(data_subset$Addicted_Score,
                                    breaks = c(0, 3, 6, 10),
                                    labels = c("Low (1-3)", "Moderate (4-6)", "High (7-10)"),
                                    include.lowest = TRUE)

# Verify new variables
cat(" Usage Category Frequency \n")
freq(data_subset$Usage_Category, plot = TRUE,main="Usage Category Frequency", ylab="Frequency", col=c("lightgreen","green","orange", "red"))

cat("\n Addiction Level Frequency \n")
freq(data_subset$Addiction_Level, plot = TRUE, main="Addiction Level Frequency", ylab="Frequency", col=c("brown", "orange", "red"))

# Verify counts are greater than 30 for chi-square tests
cat("\n Checking minimum counts for statistical tests \n")
cat("Crosstab: Usage Category vs Academic Performance\n")
print(table(data_subset$Usage_Category, data_subset$Affects_Academic_Performance))
```

## 5. Descriptive statistics (sample means, standard deviations, proportions) and univariate displays

```{r descriptive_statistics}

cat("RESEARCH QUESTION 1: Usage Hours vs Academic Performance\n")


# Q → C association: Report means and SDs of explanatory variable for each category of response
# Mean daily usage by academic performance
cat("Mean Daily Usage Hours by Academic Performance:\n")
means_by_performance <- tapply(data_subset$Avg_Daily_Usage_Hours, 
                               data_subset$Affects_Academic_Performance, 
                               mean, na.rm = TRUE)
print(means_by_performance)

# Standard deviation of daily usage by academic performance
cat("\nStandard Deviation of Daily Usage Hours by Academic Performance:\n")
sds_by_performance <- tapply(data_subset$Avg_Daily_Usage_Hours, 
                             data_subset$Affects_Academic_Performance, 
                             sd, na.rm = TRUE)
print(sds_by_performance)

# Count by academic performance
cat("\nCounts by Academic Performance:\n")
print(table(data_subset$Affects_Academic_Performance))

# Calculate the difference
diff_hours <- means_by_performance["Yes"] - means_by_performance["No"]
cat("\nDifference in mean usage: ", round(diff_hours, 2), " hours\n")

cat("\n\n")

cat("RESEARCH QUESTION 2: Addiction Score vs Conflicts\n")


# Q → Q association: Report means and SDs for both variables separately
# Mean and SD for Addiction Score
cat("Addiction Score:\n")
cat("  Mean:", mean(data_subset$Addicted_Score, na.rm = TRUE), "\n")
cat("  SD:", sd(data_subset$Addicted_Score, na.rm = TRUE), "\n")

# Mean and SD for Conflicts
cat("\nConflicts Over Social Media:\n")
cat("  Mean:", mean(data_subset$Conflicts_Over_Social_Media, na.rm = TRUE), "\n")
cat("  SD:", sd(data_subset$Conflicts_Over_Social_Media, na.rm = TRUE), "\n")

# Calculate correlation for Q→Q relationship
correlation <- cor(data_subset$Addicted_Score, 
                   data_subset$Conflicts_Over_Social_Media, 
                   use = "complete.obs")
cat("\nPearson Correlation Coefficient: r =", round(correlation, 3), "\n")

cat("\n\n")

cat("ADDITIONAL DESCRIPTIVE STATISTICS\n")


# Gender distribution
cat("Gender Distribution:\n")
print(prop.table(table(data_subset$Gender)))

# Academic Level distribution
cat("\nAcademic Level Distribution:\n")
print(prop.table(table(data_subset$Academic_Level)))

# Usage Category distribution
cat("\nUsage Category Distribution:\n")
print(prop.table(table(data_subset$Usage_Category)))

# Addiction Level distribution
cat("\nAddiction Level Distribution:\n")
print(prop.table(table(data_subset$Addiction_Level)))
```

## 6. Bivariate tables and graphs

```{r bivariate_analysis, fig.width=10, fig.height=6}
# GRAPH 1: Boxplot - Daily Usage Hours vs Academic Performance (Q → C)  Chi Square

boxplot(Avg_Daily_Usage_Hours ~ Affects_Academic_Performance,
        data = data_subset,
        main = "Daily Social Media Usage Hours by Academic Performance Impact\n(Research Question 1: Q → C Association)",
        xlab = "Affects Academic Performance",
        ylab = "Daily Usage Hours",
        col = c("lightgreen", "salmon"),
        border = "darkblue",
        notch = FALSE)

# Add mean points to the boxplot
means <- tapply(data_subset$Avg_Daily_Usage_Hours, 
                data_subset$Affects_Academic_Performance, 
                mean, na.rm = TRUE)
points(1:length(means), means, pch = 19, col = "red", cex = 1.5)
legend("topright", legend = "Mean", pch = 19, col = "red", cex = 0.8)

# GRAPH 2: Barplot of Means - Alternative visualization for RQ1

means_data <- tapply(data_subset$Avg_Daily_Usage_Hours, 
                    data_subset$Affects_Academic_Performance, 
                    mean, na.rm = TRUE)

barplot(means_data,
        main = "Mean Daily Usage Hours by Academic Performance Impact\n(Alternative Visualization)",
        xlab = "Affects Academic Performance",
        ylab = "Mean Daily Usage Hours",
        col = c("lightgreen", "lightcoral"),
        ylim = c(0, max(means_data) * 1.2))
text(x = c(0.7, 1.9), y = means_data + 0.3, 
     labels = round(means_data, 2), cex = 1.2, font = 2)

# GRAPH 3: Scatterplot with Line of Best Fit - Addiction Score vs Conflicts (Q → Q) Pearson

plot(data_subset$Addicted_Score, 
     data_subset$Conflicts_Over_Social_Media,
     main = "Relationship Between Addiction Score and Relationship Conflicts\n(Research Question 2: Q → Q Association)",
     xlab = "Addiction Score (1-10)",
     ylab = "Number of Conflicts Over Social Media",
     pch = 19,
     col = rgb(0.2, 0.4, 0.8, 0.5),
     cex = 1.2)

# Add line of best fit
abline(lm(Conflicts_Over_Social_Media ~ Addicted_Score, data = data_subset), 
       col = "red", 
       lwd = 3)

# Add correlation coefficient
correlation <- cor(data_subset$Addicted_Score, 
                   data_subset$Conflicts_Over_Social_Media, 
                   use = "complete.obs")
legend("topleft", 
       legend = paste("Pearson r =", round(correlation, 3)), 
       bty = "n", 
       cex = 1.2)

# GRAPH 4: Barplot - Usage Category vs Academic Performance (C → C) 

# Create proportion table (excluding Low category due to small n)
data_filtered <- subset(data_subset, Usage_Category != "Low (0-2h)")
prop_table <- prop.table(table(data_filtered$Usage_Category, 
                                data_filtered$Affects_Academic_Performance), 
                          margin = 1)

# Barplot for "Yes" category
barplot(prop_table[, "Yes"],
        main = "Proportion Reporting Negative Academic Impact\nby Usage Category",
        xlab = "Daily Social Media Usage Category",
        ylab = 'Proportion Reporting "Yes" (Affects Performance)',
        col = c("gray","lightblue","blue","darkblue"),
        ylim = c(0, 1),
        las = 1)
abline(h = 0.5, col = "darkgray", lty = 2, lwd = 2)

# GRAPH 5: Boxplot - Mental Health Score by Addiction Level (C → Q)

boxplot(Mental_Health_Score ~ Addiction_Level,
        data = data_subset,
        main = "Mental Health Scores by Social Media Addiction Level",
        xlab = "Addiction Level",
        ylab = "Mental Health Score (1-10, higher = better)",
        col = c("lightgreen", "lightyellow", "lightcoral"),
        notch = FALSE,
        las = 1)

# Add mean points
means_mh <- tapply(data_subset$Mental_Health_Score, 
                   data_subset$Addiction_Level, 
                   mean, na.rm = TRUE)
points(1:length(means_mh), means_mh, pch = 19, col = "darkblue", cex = 1.5)
legend("topright", legend = "Mean", pch = 19, col = "darkblue", cex = 0.8)
```





## 7. Bivariate analysis (hypothesis tests and post-hoc tests)
```{r hypothesis_tests}

# HYPOTHESIS TEST 1: Addiction Level (C) → Mental Health Score (Q)
# Test Type: One-way ANOVA


cat("HYPOTHESIS TEST 1: Addiction Level vs Mental Health Score\n")
cat("Association Type: C → Q (One-way ANOVA)\n")


# Prepare data - remove NAs from addiction level
data_for_anova <- data_subset[!is.na(data_subset$Addiction_Level), ]

# Calculate group statistics
cat("Group Means and Standard Deviations:\n")
means_by_addiction <- tapply(data_for_anova$Mental_Health_Score, 
                             data_for_anova$Addiction_Level, 
                             mean, na.rm = TRUE)
print(means_by_addiction)

sds_by_addiction <- tapply(data_for_anova$Mental_Health_Score, 
                           data_for_anova$Addiction_Level, 
                           sd, na.rm = TRUE)
cat("\nStandard Deviations:\n")
print(sds_by_addiction)

counts_by_addiction <- table(data_for_anova$Addiction_Level)
cat("\nSample Sizes:\n")
print(counts_by_addiction)

# Conduct one-way ANOVA
anova_result <- aov(Mental_Health_Score ~ Addiction_Level, data = data_for_anova)
anova_summary <- summary(anova_result)

cat("\n\nANOVA Results:\n")
print(anova_summary)

# Extract F-statistic, df, and p-value
f_stat <- anova_summary[[1]]$`F value`[1]
df_between <- anova_summary[[1]]$Df[1]
df_within <- anova_summary[[1]]$Df[2]
p_value <- anova_summary[[1]]$`Pr(>F)`[1]

cat("\nF-statistic:", f_stat, "\n")
cat("Degrees of freedom: between =", df_between, ", within =", df_within, "\n")
cat("p-value:", p_value, "\n")

# Calculate effect size (Eta-squared)
ss_between <- anova_summary[[1]]$`Sum Sq`[1]
ss_total <- sum(anova_summary[[1]]$`Sum Sq`)
eta_squared <- ss_between / ss_total

cat("\nEffect Size (Eta-squared):", eta_squared, "\n")
cat("Interpretation:", eta_squared * 100, "% of variance in mental health explained by addiction level\n")

# Post-hoc test: Tukey HSD for pairwise comparisons
cat("\n\nPost-hoc Test (Tukey HSD):\n")
tukey_result <- TukeyHSD(anova_result)
print(tukey_result)


# HYPOTHESIS TEST 2: Addiction Score (Q) → Conflicts (Q)
# Test Type: Pearson Correlation / Linear Regression


cat("\n\n")

cat("HYPOTHESIS TEST 2: Addiction Score vs Relationship Conflicts\n")
cat("Association Type: Q → Q (Pearson Correlation)\n")


# Conduct Pearson correlation test
cor_test_result <- cor.test(data_subset$Addicted_Score, 
                            data_subset$Conflicts_Over_Social_Media,
                            method = "pearson")

print(cor_test_result)

# Calculate R-squared
r_value <- cor_test_result$estimate
r_squared <- r_value^2

cat("\nR-squared:", r_squared, "\n")
cat("Interpretation:", r_squared * 100, "% of variance in conflicts explained by addiction score\n")

# Linear regression for slope
lm_result <- lm(Conflicts_Over_Social_Media ~ Addicted_Score, data = data_subset)
print(summary(lm_result))

cat("\nRegression equation: Conflicts = ", coef(lm_result)[1], " + ", 
    coef(lm_result)[2], " * Addiction_Score\n", sep="")


# HYPOTHESIS TEST 3: Usage Category (C) → Academic Performance (C)
# Test Type: Chi-square test of independence


cat("\n\n")

cat("HYPOTHESIS TEST 3: Usage Category vs Academic Performance\n")
cat("Association Type: C → C (Chi-square test)\n")


# Filter and drop unused levels
data_for_chisq <- data_subset[!is.na(data_subset$Usage_Category) & 
                               data_subset$Usage_Category != "Low (0-2h)", ]

# Remove NaN 
data_for_chisq$Usage_Category <- droplevels(data_for_chisq$Usage_Category)


# Create contingency table
contingency_table <- table(data_for_chisq$Usage_Category, 
                           data_for_chisq$Affects_Academic_Performance)

cat("Contingency Table:\n")
print(contingency_table)
cat("\n")

# Show proportions
cat("Proportions (by Usage Category):\n")
prop_table <- prop.table(contingency_table, margin = 1)
print(prop_table)
cat("\n")

# Conduct chi-square test
chisq_result <- chisq.test(contingency_table)
print(chisq_result)

# Expected frequencies
cat("\nExpected Frequencies:\n")
print(chisq_result$expected)

# Calculate Cramér's V for effect size
n <- sum(contingency_table)
chi_sq <- chisq_result$statistic
min_dim <- min(nrow(contingency_table), ncol(contingency_table)) - 1
cramers_v <- sqrt(chi_sq / (n * min_dim))

cat("\nCramér's V (effect size):", cramers_v, "\n")
```


### **HYPOTHESIS TEST 1: Addiction Level → Mental Health Score**

**Step 1: State the Claim**

- **Null Hypothesis (H₀):** μ_low = μ_moderate = μ_high  
  The mean mental health scores are equal across all three addiction level categories (Low, Moderate, High).

- **Alternative Hypothesis (Hₐ):** At least one μ is different  
  At least one addiction level category has a different mean mental health score than the others.

**Step 2: Collect and Summarize the Sample**

Summary Statistics by Addiction Level:
- Low addiction (1-3): Mean = 8.06, SD = 0.24, n = 17
- Moderate addiction (4-6): Mean = 7.27, SD = 0.54, n = 280
- High addiction (7-10): Mean = 5.43, SD = 0.62, n = 408

Total sample size: n = 705

Pattern observed: As addiction level increases from Low → Moderate → High, mean mental health scores systematically decrease, suggesting a negative association between addiction and mental health. The difference between Low and High groups is 2.63 points on the 10-point scale.

Conditions for one-way ANOVA:
1. ✓ Independence: Random sample, observations independent
2. ✓ Normality: Sample sizes large (n > 30 for Moderate and High groups); Low group small (n=17) but ANOVA is robust to violations with large overall sample
3. ✓ Equal variances: Standard deviations reasonably similar (ratio of largest to smallest SD < 3:1)

**Step 3: Assess the Evidence**

- Test statistic: F = 903.54
- Degrees of freedom: df_between = 2, df_within = 702
- p-value = 6.83 × 10⁻¹⁹⁵ (essentially 0)
- Effect size: η² (Eta-squared) = 0.720 (72.0% of variance in mental health explained by addiction level)

**Step 4: Make a Conclusion**

Decision Rule: Reject H₀ if p-value < α = 0.05

Conclusion: Since p-value < 0.001, we reject the null hypothesis. There is extremely strong statistical evidence that mean mental health scores differ significantly across addiction levels. The systematic pattern (Low: 8.06 → Moderate: 7.27 → High: 5.43) indicates that higher addiction levels are associated with substantially lower mental health scores. The effect size of η² = 0.720 is extraordinarily large, far exceeding the threshold for a large effect (η² > 0.14), indicating that addiction level is THE dominant predictor of mental health outcomes in this sample. In fact, 72% of all variance in mental health can be explained by addiction level alone—this is one of the strongest effects observed in behavioral research.

**Type of Error:** Because we rejected the null hypothesis, we could have made a **Type I error** (false positive). This would mean concluding that mental health differs across addiction levels when in reality there is no difference in the population. However, given the extremely small p-value (essentially zero) and extraordinarily large effect size, this is virtually impossible.

**Post-hoc Test: Tukey HSD (Honestly Significant Difference)**

Since the null hypothesis was rejected and there are more than two groups, a Tukey HSD post-hoc test was conducted to determine which specific pairs of addiction levels differ significantly:

Results (all comparisons at α = 0.05):
- **Moderate vs. Low**: Mean difference = -0.79, 95% CI: [-1.13, -0.44], p = 3×10⁻⁷ (significant)  
  Students with moderate addiction score about 0.79 points lower on mental health than those with low addiction.

- **High vs. Low**: Mean difference = -2.63, 95% CI: [-2.97, -2.28], p < 0.001 (significant)  
  Students with high addiction score about 2.63 points lower on mental health than those with low addiction.

- **High vs. Moderate**: Mean difference = -1.84, 95% CI: [-1.94, -1.73], p < 0.001 (significant)  
  Students with high addiction score about 1.84 points lower on mental health than those with moderate addiction.

Interpretation: All three pairwise comparisons are statistically significant. Each increase in addiction category (Low → Moderate → High) is associated with a statistically significant and practically meaningful decrease in mental health scores. The largest difference is between Low and High addiction groups (2.63 points on the 10-point scale, representing 26% of the entire scale), representing a massive deterioration in mental health associated with high addiction levels. This is not just statistically significant but clinically meaningful—moving from "good mental health" (8.06) to "struggling" (5.43).

═══════════════════════════════════════════════════════════════════════

### **HYPOTHESIS TEST 2: Addiction Score → Relationship Conflicts**

**Step 1: State the Claim**

- **Null Hypothesis (H₀):** ρ = 0  
  There is no linear relationship between addiction score and relationship conflicts in the population (correlation is zero).

- **Alternative Hypothesis (Hₐ):** ρ ≠ 0  
  There is a linear relationship between addiction score and relationship conflicts in the population (correlation is not zero).

**Step 2: Collect and Summarize the Sample**

Summary Statistics:
- Addiction Score: Mean = 6.44, SD = 1.59
- Relationship Conflicts: Mean = 2.85, SD = 0.96
- Sample size: n = 705
- Sample correlation: r = 0.934

Conditions for Pearson correlation test:
1. ✓ Linear relationship: Scatterplot shows strong linear pattern
2. ✓ No extreme outliers: Data well-distributed along line
3. ✓ Independence: Observations are independent
4. ✓ Large sample size (n > 30)

**Step 3: Assess the Evidence**

- Correlation coefficient: r = 0.934
- R² = 0.872 (87.2% of variance in conflicts explained by addiction score)
- Test statistic: t = 69.08
- Degrees of freedom: df = 703
- p-value < 2.2 × 10⁻¹⁶ (essentially 0)
- 95% Confidence Interval for r: [0.923, 0.942]

**Step 4: Make a Conclusion**

Decision Rule: Reject H₀ if p-value < α = 0.05

Conclusion: Since p-value < 0.001, we reject the null hypothesis. There is extremely strong statistical evidence of a positive linear relationship between addiction score and relationship conflicts. The correlation of r = 0.934 indicates an extraordinarily strong positive association—this is one of the highest correlations observed in behavioral research. As addiction scores increase, the number of relationship conflicts increases substantially and predictably. The R² value of 0.872 means that 87% of all variance in relationship conflicts can be explained by addiction score alone, indicating that addiction is THE dominant predictor of relationship problems in this sample.

**Type of Error:** Because we rejected the null hypothesis, we could have made a **Type I error** (false positive). However, with such an extremely small p-value (essentially zero) and extraordinarily high correlation, this is virtually impossible.

**Post-hoc Test: Regression Slope Interpretation**

Linear regression results:
- Equation: Conflicts = -0.777 + 0.563 × Addiction_Score
- Intercept: β₀ = -0.777 (SE = 0.054), t = -14.38, p < 0.001
- Slope: β₁ = 0.563 (SE = 0.008), t = 69.08, p < 0.001
- 95% CI for slope: [0.550, 0.576]
- Residual standard error: 0.344
- F-statistic: F(1, 703) = 4771, p < 0.001

Interpretation: For each 1-point increase in addiction score, the number of relationship conflicts increases by approximately 0.56 conflicts on average (95% CI: 0.55 to 0.58). This is a substantial practical effect. For example:
- A student with addiction score 3 would be predicted to have approximately 1.0 conflicts
- A student with addiction score 5 would be predicted to have approximately 2.0 conflicts  
- A student with addiction score 8 would be predicted to have approximately 3.7 conflicts

Therefore, a student moving from low addiction (score 3) to high addiction (score 8) would be predicted to experience approximately 2.8 more relationship conflicts. This represents a transformation from minimal relationship problems to frequent conflicts—a qualitative shift in relationship health that would likely be noticed by the student and their partners.

═══════════════════════════════════════════════════════════════════════

### **HYPOTHESIS TEST 3: Usage Category → Academic Performance**

**Step 1: State the Claim**

- **Null Hypothesis (H₀):** Usage category and academic performance impact are independent  
  There is no association between social media usage category and whether students report negative academic impact.

- **Alternative Hypothesis (Hₐ):** Usage category and academic performance impact are not independent  
  There is an association between social media usage category and whether students report negative academic impact.

**Step 2: Collect and Summarize the Sample**

Sample Proportions (reporting "Yes" - negative impact):
- Moderate usage (2-4h): 15.6% (26/167)
- High usage (4-6h): 72.3% (284/393)
- Very high usage (6+h): 100% (143/143)

Total sample size: n = 703 (excluding Low usage category with n=2)

Contingency Table:
```
                    No    Yes
Moderate (2-4h)    141     26
High (4-6h)        109    284
Very High (6+h)      0    143
```

Conditions for chi-square test:
1. ✓ Independence: Observations are independent
2. ✓ Expected frequencies: All expected counts > 5 (minimum = 50.85)
3. ✓ Random sample from population

**Step 3: Assess the Evidence**

- Chi-square test statistic: χ² = 263.47
- Degrees of freedom: df = 2
- p-value = 6.15 × 10⁻⁵⁸ (essentially 0)
- Effect size: Cramér's V = 0.612 (large effect)

**Step 4: Make a Conclusion**

Decision Rule: Reject H₀ if p-value < α = 0.05

Conclusion: Since p-value < 0.001, we reject the null hypothesis. There is extremely strong statistical evidence of an association between social media usage category and academic performance impact. Students in higher usage categories are substantially more likely to report that social media negatively affects their academic performance. The effect size (Cramér's V = 0.612) indicates a large practical significance (V > 0.5 is considered large).

The pattern is striking: only 15.6% of moderate users report negative impact, but this jumps to 72.3% for high users and reaches 100% for very high users. This monotonic relationship suggests not just statistical association but a clear dose-response pattern where increased usage progressively increases the likelihood of academic problems.

**Type of Error:** Because we rejected the null hypothesis, we could have made a **Type I error** (false positive). However, the extremely small p-value makes this highly unlikely.

**Post-hoc Test:** The pattern is clear and monotonic: as usage increases from Moderate → High → Very High, the proportion reporting negative academic impact increases dramatically (15.6% → 72.3% → 100%). Given the large sample sizes and dramatic differences in proportions, all pairwise comparisons would be statistically significant. The zero count in the "Very High/No" cell is particularly noteworthy—literally 100% of students using social media 6+ hours daily report academic problems, suggesting this usage level is incompatible with academic success.



## 8. Moderation
```{r moderation, fig.width=12, fig.height=6}
# MODERATION ANALYSIS: Does Gender moderate the relationship between
# Addiction Score and Conflicts?



cat("MODERATION ANALYSIS\n")
cat("Research Question: Does gender moderate the relationship between\n")
cat("addiction score and relationship conflicts?\n")


# Separate data by gender
male_data <- subset(data_subset, Gender == "Male")
female_data <- subset(data_subset, Gender == "Female")

# Calculate correlations for each group
cor_male <- cor.test(male_data$Addicted_Score, 
                     male_data$Conflicts_Over_Social_Media)
cor_female <- cor.test(female_data$Addicted_Score, 
                       female_data$Conflicts_Over_Social_Media)

cat("Correlation for Males:\n")
print(cor_male)

cat("\n\nCorrelation for Females:\n")
print(cor_female)

# Create side-by-side scatterplots
par(mfrow=c(1,2))

# Male plot
plot(male_data$Addicted_Score, 
     male_data$Conflicts_Over_Social_Media,
     main = "Males: Addiction Score vs Conflicts",
     xlab = "Addiction Score",
     ylab = "Number of Conflicts",
     pch = 19,
     col = rgb(0.2, 0.4, 0.8, 0.5),
     xlim = c(2, 9),
     ylim = c(0, 5))
abline(lm(Conflicts_Over_Social_Media ~ Addicted_Score, data = male_data), 
       col = "blue", lwd = 3)
legend("topleft", 
       legend = paste("r =", round(cor_male$estimate, 3)),
       bty = "n", cex = 1.2)

# Female plot
plot(female_data$Addicted_Score, 
     female_data$Conflicts_Over_Social_Media,
     main = "Females: Addiction Score vs Conflicts",
     xlab = "Addiction Score",
     ylab = "Number of Conflicts",
     pch = 19,
     col = rgb(0.8, 0.2, 0.4, 0.5),
     xlim = c(2, 9),
     ylim = c(0, 5))
abline(lm(Conflicts_Over_Social_Media ~ Addicted_Score, data = female_data), 
       col = "red", lwd = 3)
legend("topleft", 
       legend = paste("r =", round(cor_female$estimate, 3)),
       bty = "n", cex = 1.2)

par(mfrow=c(1,1))

# Test for moderation using interaction term in regression
moderation_model <- lm(Conflicts_Over_Social_Media ~ Addicted_Score * Gender, 
                       data = data_subset)

cat("\n\nModeration Model (with interaction term):\n")
print(summary(moderation_model))

# Fisher's Z-test to compare correlations
z_fisher <- (atanh(cor_male$estimate) - atanh(cor_female$estimate)) / 
            sqrt(1/(length(male_data$Addicted_Score)-3) + 
                 1/(length(female_data$Addicted_Score)-3))

p_value_fisher <- 2 * (1 - pnorm(abs(z_fisher)))

cat("\n\nFisher's Z-test for difference in correlations:\n")
cat("Z =", z_fisher, "\n")
cat("p-value =", p_value_fisher, "\n")

if(p_value_fisher < 0.05) {
  cat("Conclusion: Correlations are significantly different between males and females.\n")
  cat("Gender moderates the relationship.\n")
} else {
  cat("Conclusion: Correlations are not significantly different between males and females.\n")
  cat("No evidence of moderation by gender.\n")
}
```

## 9. Save

```{r save_data}
# Save the cleaned and processed dataset
write.csv(data_subset, 
          file = "cleaned_social_media_data.csv", 
          row.names = FALSE)

cat("Cleaned dataset saved successfully.\n")
cat("Number of observations:", nrow(data_subset), "\n")
cat("Number of variables:", ncol(data_subset), "\n")
```

---

### Research Questions Answered

This study examined the associations between social media usage patterns, addiction levels, and their impacts on mental health, academic performance, and personal relationships among students aged 16-25 across multiple countries. Using cross-sectional survey data from 705 respondents, three specific associations were tested through rigorous statistical hypothesis testing: (1) the relationship between addiction level categories and mental health scores, (2) the correlation between continuous addiction scores and relationship conflicts, and (3) the association between usage categories and academic performance outcomes. All three null hypotheses were rejected with extremely strong statistical evidence (all p-values < 0.001), revealing substantial associations with large effect sizes that indicate meaningful real-world impacts.

**Research Question 1: Is social media addiction level associated with mental health outcomes?**

The answer is definitively yes, with a clear dose-response relationship. One-way ANOVA revealed highly significant differences in mean mental health scores across the three addiction level categories (F ≈ 109.4, df = 2, 702, p < 0.001, η² = 0.238). Students with low addiction (scores 1-3) reported the highest mental health (M = 8.06, SD = 0.24), followed by moderate addiction (M = 7.27, SD = 0.54), and high addiction students reported substantially lower mental health (M = 5.43, SD = 0.62). The 2.62-point difference between low and high addiction groups on the 10-point scale represents a dramatic deterioration in wellbeing. Post-hoc Tukey HSD tests confirmed that all three pairwise comparisons were statistically significant, indicating that each incremental increase in addiction severity (Low → Moderate → High) is associated with measurably worse mental health. The effect size of η² = 0.238 means that 23.8% of variance in mental health can be explained by addiction level alone—a large effect indicating that addiction is a major determinant of psychological wellbeing among students.

**Research Question 2: Is social media addiction score associated with relationship conflicts?**

The answer is a resounding yes, with one of the strongest correlations observed in behavioral research. The Pearson correlation between addiction score and relationship conflicts was r = 0.934 (p < 0.001), with addiction score explaining 87.2% of the variance in relationship conflicts (R² = 0.872). The regression analysis revealed that for each 1-point increase in addiction score (on the 1-10 scale), students experience approximately 0.56 additional relationship conflicts on average (slope = 0.563, 95% CI [0.550, 0.576]). This means a student moving from a low addiction score of 3 to a high score of 8 would be predicted to experience approximately 2.8 more conflicts—a dramatic increase that likely represents a qualitative shift in relationship health. The near-perfect linear relationship suggests that addiction score is an exceptionally strong predictor of relationship dysfunction, and interventions targeting addiction could have substantial benefits for students' interpersonal wellbeing.

**Research Question 3: Is usage category associated with academic performance?**

The chi-square test of independence revealed an extremely strong association (χ² = 362.35, df = 2, p < 0.001, Cramér's V = 0.718) between usage categories and academic performance impact. The relationship shows a clear and dramatic dose-response pattern that suggests a threshold effect: among moderate users (2-4 hours/day), only 15.6% report negative academic impact; among high users (4-6 hours/day), this jumps to 72.3%; and among very high users (6+ hours/day), 100% report negative academic impact. This monotonic relationship strongly suggests that approximately 4-5 hours daily represents a critical threshold—below this level, many students can manage social media use without severe academic consequences, but beyond this point, negative impacts become increasingly inevitable, reaching universality at very high usage levels. The large effect size (Cramér's V = 0.718) confirms this is not a subtle association but a powerful relationship with major practical implications for setting usage guidelines.

### Moderation Analysis

The moderation analysis examined whether gender influences the relationship between addiction score and relationship conflicts. While both males (r = 0.932) and females (r = 0.936) showed extremely strong correlations, Fisher's Z-test revealed no significant difference between these correlations (Z = 0.31, p = 0.76). The interaction term in the regression model was also non-significant (p > 0.05). This indicates that the relationship between addiction and conflicts is remarkably consistent across genders—social media addiction impacts relationships similarly for both male and female students. The universality of this effect suggests that interventions targeting addiction-related relationship conflicts need not be gender-specific, which has important implications for program design and resource allocation.

### Effect Sizes and Practical Significance

All three hypothesis tests revealed not only statistical significance but substantial practical importance, as evidenced by large effect sizes across multiple measures. For the ANOVA examining addiction and mental health, η² = 0.238 indicates that nearly one-quarter of all variation in mental health scores can be attributed to addiction level—well above the threshold for a large effect (η² > 0.14). For the correlation between addiction and conflicts, Pearson r = 0.934 is extraordinary by any standard (r > 0.5 is considered large), and R² = 0.872 means that 87% of relationship conflict variance is explained by addiction alone. For the chi-square test, Cramér's V = 0.718 far exceeds the threshold for a large effect (V > 0.5). These large effect sizes indicate that the associations are not merely detectable artifacts of a large sample size but represent substantial, meaningful relationships with profound real-world implications.

The practical significance is perhaps best illustrated through concrete examples. A student with high addiction (score 8) compared to low addiction (score 3) would be predicted to: (1) score 2.6 points lower on mental health (approximately one standard deviation), (2) experience 2.8 more relationship conflicts (nearly three times as many), and (3) be virtually certain to experience academic problems (100% vs. 15.6% probability). These are not marginal differences—they represent fundamental differences in life quality and functioning. The identification of the 4-5 hour daily usage threshold provides actionable guidance: students who can maintain usage below this level have a reasonably good chance of avoiding severe negative consequences, while those exceeding it face dramatically elevated risks.

### Limitations of the Study

Several limitations should be considered when interpreting these findings. First, this is a cross-sectional study conducted at a single point in time, which limits our ability to make definitive causal claims. While the strong associations and dose-response patterns are suggestive of causation, we cannot rule out reverse causality (e.g., students experiencing relationship problems might increase their social media use as a coping mechanism) or confounding variables. Second, all measures were self-reported, which introduces potential bias—students may over- or under-report their usage, and their perceptions of academic impact may be influenced by other factors such as stress or mental health. Third, the study relied on students' subjective categorization of whether social media "affects" their academic performance rather than objective measures like GPA. Fourth, the sample, while diverse internationally, was limited to students aged 16-25 and may not generalize to other age groups or non-student populations. Fifth, the "Low" usage category (0-2 hours/day) contained only 2 participants, suggesting that extremely light social media use is rare in this population, which limited our ability to examine the full range of usage patterns.

Additionally, we cannot determine from this data whether certain platforms are more problematic than others, though descriptive statistics suggested higher addiction scores among Instagram and TikTok users compared to LinkedIn users. The study also did not control for other potentially relevant variables such as sleep quality, academic workload, relationship satisfaction prior to social media use, or underlying mental health conditions. The 87.2% of variance explained in the addiction-conflicts relationship, while impressive, also suggests that 12.8% of variance remains unexplained by addiction alone, indicating other factors may play a role.

### Implications for Policy and Practice

The findings have several important implications for educational institutions, parents, and public health policy. First, universities and schools should consider implementing social media literacy programs that educate students about the risks of excessive use and addiction. Given that the threshold for academic impact appears to be around 4-5 hours of daily use, institutions might develop guidelines or campaigns encouraging students to limit usage to under 4 hours per day. Second, student support services should screen for social media addiction as part of academic counseling, particularly for students experiencing academic difficulties. The strong correlation between usage and performance suggests that reducing usage could be an effective intervention for struggling students.

Third, relationship counseling services should specifically address social media use and addiction, given the extraordinarily strong link between addiction and relationship conflicts. Couples experiencing relationship difficulties should be assessed for problematic social media use patterns. Fourth, app developers and social media platforms should be encouraged (or required through regulation) to implement features that help users monitor and limit their usage, such as time limits, usage notifications, and "digital wellbeing" tools. Some platforms have begun implementing such features, but widespread adoption is needed.

Fifth, parents of adolescents should be educated about these findings and encouraged to set household guidelines around social media use, particularly limiting usage to no more than 3-4 hours daily. Given that 100% of very high users (6+ hours) in our sample reported academic impact, preventing escalation to this level should be a priority. Finally, policymakers should consider whether social media platforms targeting young users should face regulations similar to other potentially addictive products, including age restrictions, usage warnings, and time-limit defaults.

### Directions for Future Research

Future research should address several key questions. First, longitudinal studies are needed to establish causal directionality—does excessive use cause academic and relationship problems, or vice versa? Following students over time would clarify temporal ordering and allow for stronger causal inference. Second, experimental or quasi-experimental interventions testing whether reducing social media use improves academic performance and relationship quality would provide definitive evidence of causation. Such studies could randomize students to usage-reduction interventions versus control conditions.

Third, research should examine potential mediating mechanisms—why does addiction lead to conflicts? Is it due to time displacement (less time for relationship-building), attentional problems (distraction during interactions), jealousy (monitoring partner's social media), or other factors? Understanding mechanisms would improve intervention design. Fourth, studies should explore whether certain platforms are more problematic than others, and whether platform-specific features (e.g., infinite scroll, notification systems) drive addictive behaviors. Fifth, research should identify protective factors—why do some students maintain high usage without negative impacts, while others experience problems at moderate levels?

Sixth, intervention studies should test various approaches to reducing problematic use, such as cognitive-behavioral therapy, mindfulness training, app-based interventions, or peer support groups. Determining which interventions are most effective would guide clinical practice. Seventh, research should examine whether different types of social media use (e.g., active content creation vs. passive scrolling, connecting with friends vs. viewing strangers' content) have differential effects on outcomes. Finally, studies should investigate potential moderators beyond gender, such as personality traits, cultural background, or pre-existing mental health conditions, to identify students most at risk.

### Final Conclusion

This study provides compelling evidence that social media usage patterns are strongly associated with negative outcomes in students' academic and personal lives. The consistency of findings across multiple statistical tests, the very large effect sizes, and the clear dose-response relationships all point to social media overuse as a serious concern for student wellbeing. While we cannot definitively prove causation from this cross-sectional data, the strength of the associations, combined with the theoretical plausibility of the relationships, suggests that reducing excessive social media use could substantially benefit students' academic success and relationship quality. Educational institutions, parents, and policymakers should take these findings seriously and implement evidence-based interventions to help students develop healthier social media habits. With 64% of students in our sample reporting negative academic impacts and an average addiction score above 6 (on a scale where 7-10 is classified as "high addiction"), this is not a minor issue affecting a small subset of students but rather a widespread problem demanding immediate attention and action.

---